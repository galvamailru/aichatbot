# Варианты решения: AI-чат в iframe (Python, Docker, PostgreSQL)

Исходная постановка: см. `01-problem-statement.md`.

---

## Вариант 1. REST без стриминга (FastAPI, один запрос — один ответ)

**Суть:** FastAPI-сервер, один HTTP POST с сообщением пользователя, синхронный вызов LLM DeepSeek, возврат полного ответа в теле ответа. Чат в iframe — форма + список сообщений, обновление после каждого ответа.

**Изменения:** Один модуль приложения (FastAPI), один роутер для чата, таблица в PostgreSQL (пользователь, сессия/диалог, сообщения), чтение .env и файла промпта при старте, конфигурируемый URL LLM.

**Риски:** Долгий ответ LLM блокирует запрос; при таймауте возможна потеря ответа; UX «зависания» на время генерации.

**Плюсы:** Минимальная реализация, быстрый старт, простая отладка и тесты.  
**Минусы:** Плохой UX при длинных ответах, нет индикации «печати».

---

## Вариант 2. REST + Server-Sent Events (FastAPI, стриминг ответа LLM)

**Суть:** FastAPI, один POST для отправки сообщения пользователя, ответ — поток SSE с токенами от LLM. Сохранение диалога в PostgreSQL после завершения стрима (или по мере поступления — на усмотрение). Клиент в iframe подписывается на SSE и пошагово отображает ответ.

**Изменения:** Эндпоинт отправки сообщения + эндпоинт/подписка на SSE-поток для конкретного запроса; таблицы БД те же (user_id, диалог, сообщения); конфиг и промпт — как в варианте 1.

**Риски:** Управление жизненным циклом стрима (таймауты, обрыв соединения); необходимость идентификации потока (например, по id запроса).

**Плюсы:** Хороший UX (ответ «печатается»), без усложнения до очередей/воркеров.  
**Минусы:** Чуть сложнее варианта 1, клиент в iframe должен уметь работать с SSE.

---

## Вариант 3. WebSocket (полный дуплекс)

**Суть:** Один WebSocket на сессию: клиент в iframe отправляет сообщения и получает поток токенов по тому же соединению. Сервер (FastAPI с WebSocket) принимает сообщение, вызывает LLM (стрим), шлёт токены в сокет, по завершении пишет в PostgreSQL.

**Изменения:** WebSocket-эндпоинт вместо/в дополнение к REST; страница для iframe с WS-клиентом; та же схема БД и конфиг.

**Риски:** Поведение WebSocket в iframe в части браузеров/политик; необходимость переподключения при обрыве.

**Плюсы:** Естественная модель «чат», один канал.  
**Минусы:** Сложнее отлаживать и тестировать, чем простой REST/SSE.

---

## Вариант 4. Очередь задач (Celery/RQ + воркер)

**Суть:** API принимает сообщение (POST), кладёт задачу в очередь (Redis), воркер забирает задачу, вызывает LLM, сохраняет ответ в БД. Клиент либо опрашивает статус/результат (polling), либо получает уведомление через WebSocket/SSE.

**Изменения:** Redis (или брокер), воркер-процесс, модель задач, эндпоинты для постановки в очередь и получения результата; docker-compose с сервисами app, worker, redis, postgres.

**Риски:** Существенно больше компонентов; задержка из-за очереди; операционная сложность.

**Плюсы:** Масштабируемость, возможность повторных попыток, фоновая обработка.  
**Минусы:** Избыточно для встраиваемого чата с одним LLM; дольше реализация и поддержка.

---

## Сравнение по критериям

| Критерий              | Вариант 1 | Вариант 2 | Вариант 3 | Вариант 4 |
|-----------------------|-----------|-----------|-----------|-----------|
| Сопровождаемость      | Высокая   | Высокая   | Средняя   | Ниже      |
| Масштаб изменений     | Минимальный | Небольшой | Небольшой | Большой   |
| Риск регрессий        | Низкий    | Низкий    | Средний   | Выше      |
| Долгосрочная стоимость| Низкая    | Низкая    | Средняя   | Выше      |
| UX (длинные ответы)   | Слабый    | Хороший   | Хороший   | Зависит от клиента |

**Рекомендация:** Вариант 2 (REST + SSE) — баланс простоты стека, скорости реализации и приемлемого UX без введения очередей и воркеров.

**Выбран для финального вывода:** Вариант 2.
